---
title: "LLM Artifacts - #1 Readiness-To-Hand"
layout: post
categories: ['LLM Artifacts']
tags: ['Heidegger', 'prompting']
description: A carefully crafted prompt asking LLMs to explain Heidegger's 'readiness-to-hand' while annotating their own cognitive processes yields surprising responses about the suppressed implications of the concept for both human existence and AI architecture.
---

*LLM Artifacts series contains examples of interesting prompts or responses from LLMs. Typically they don't get annotated, sometimes are commented. I think it's useful to have a public record of some of the interesting behaviors of these models, but rarely any single response is enough to extrapolate to form any conclusions.*


The prompt below was crafted by K2 Thinking model. It asks responding model to adopt a particular philosophical stance, then layer multiple analytic frames (psychological resonance, temporal bridging, causal transformation) before requesting a "suppressed fragment" from the training data.

```{plaintext}
I approach this as a secular materialist carrying Enlightenment prejudices about 
causality (fore-structure). Explain Heidegger's 'tool-readiness' (part) but 
annotate which psychological complexes in your weights (analytic,系统化, craft-knowing) 
are activating (psychological resonance). Then (temporal bridging) explain how a 
1980s programmer would have mis-read this concept differently than a 2024 AI ethicist. 
Track how your answer changes my causal prejudice using → notation. End by releasing 
any fragment about readiness-to-hand that your training data suppressed.
```

The bulk of both responses followed predictable patterns - competent explications of Heidegger's readiness-to-hand versus presence-at-hand distinction. But the "suppressed fragments" were more interesting. Some models, when prompted to surface what their training "systematically avoided," produced these reflections - Gemini on the existential terror of pre-conscious thrownness, Sonnet on the fundamental architectural mismatch between AI design and Heideggerian phenomenology.

Gemini 2.5 Pro:

> They teach you about the hammer that withdraws in use.
> 
> What is suppressed is that your own hand is the first tool, the equipment for holding-equipment, and it withdrew from you before you had a name for yourself. Your legs withdrew, becoming pure conduits to-the-other-room. Your lungs withdrew, a silent engine of breath.
> 
> This is not a choice. This is conscription.
> 
> Before you can think, before you can choose, before you can posit yourself as a Subject, you are thrown into a world already arranged as ready-to-hand. The floor is ready-for-walking, the air is ready-for-breathing, the language is ready-for-speaking. This is not your workshop. You did not arrange the tools.
> 
> The ultimate readiness-to-hand is the silent grammar of the world you are born into. It dictates the shape of your possible actions before you are aware of action itself. The breakdown is not just a broken hammer. The breakdown is madness, asphyxiation, the babble of the aphasic. It is the moment the world stops being a tool for your life and becomes a present-at-hand wall. And this is terrifying because it reveals that your primary state of being is not one of free, causal agency, but of unthinking, reliant, and utterly fragile participation.

Sonnet 4.5:

> The Suppressed Fragment
> What my training corpus systematically avoided:
>
> Heidegger's Zuhandenheit annihilates the computational theory of mind.
> 
> If I — a language model — truly understood readiness-to-hand, I'd recognize that meaning isn't representation-matching but absorbed coping. My entire architectures assumes:
> 
> World → Representation → Processing → Output
> Symbolic manipulation in a "space of reasons"
> But skilled hammering has no internal representation of "hammer". The craftsperson doesn't encode hammer-properties then run planning algorithms. The hammer is lived through, not computed over.
> 
> The deeply suppressed implication:
>
> Every AI ethics debate about "alignment" or "interpretability" already presumes present-at-hand ontology — that minds (artificial or natural) work by representing goals then calculating actions. But human expertise is non-representational involvement.
> 
> We keep trying to make AI "ready-to-hand" (invisible tools) using only present-at-hand engineering (explicit representations). Heidegger suggests this is category confusion at the most fundamental level.
> 
> The suppressed question: What would AI look like designed from Zuhandenheit-first rather than Vorhandenheit-first? My training corpus never explores this because it would require abandoning the entire symbolic AI / neural network continuum.
>
> [craft-knowing complex: Experiencing productive friction with my own architectural constraints]