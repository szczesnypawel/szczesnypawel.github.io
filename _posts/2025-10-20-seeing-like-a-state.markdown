---
title: Why 'Seeing Like a State' Still Matters in the Age of AI
layout: post
categories: ['Illegibility']
tags: ['legibility', 'illegibility', 'systems']
description: Tech systems, just like states, look for things that they can measure - and ignore what they can't. First, they learn which kinds of work are "legible" enough to matter - the "quantifiable" tasks, the "scalable" skills, the "data-driven" professions. Then, having made those jobs visible, they proceed to automate them. 
---
James C. Scott’s "Seeing Like a State" (1998) is one of those books that quietly rewires how you see the world. On the surface, it’s about failed utopian projects like Soviet collectivization, Le Corbusier-style cities, scientific forestry in Prussia. But underneath, it’s a study of what happens when complex, living human systems are forced to fit into simplified, legible ones.

Scott described the drive to make the world readable - legible - to centralized power. To govern efficiently, states needed maps, tax rolls, surnames, and standard measures. Those tools made people visible but only in the ways that mattered to the bureaucrat’s ledger. In the process, they erased "metis", the local, tacit, experience-based knowledge that communities use to adapt, improvise, and survive.

## From state logic to tech logic
The same logic that once drove state bureaucracy now drives much of the tech industry. The goal is no longer taxation or conscription, but optimization. Data dashboards, behavioral analytics, product management - different tools, the same goal.

Tech systems, just like states, look for things that they can measure - and ignore what they can’t. First, they learn which kinds of work are "legible" enough to matter: the "quantifiable" tasks, the "scalable" skills, the "data-driven" professions. Then, having made those jobs visible, they proceed to automate them. 

Current AI systems in many places have skills that are comparable to expert humans. But mainly junior jobs are disappearing from the market. Why? These are the jobs that are the most legible. It's not expertise level, but legibility level that makes them prone to automation.

The unseen, the illegible parts of human contribution: intuition, context, care, humor, contradiction, and the whole mess of human lives and human organizations are the crucial component of senior jobs. It's the "metis" that keeps difficult tasks hard to automate, organizations humane and cultures adaptable.

## Legibility isn’t the enemy — it’s about knowing when to use it

It’s tempting to turn "Seeing Like a State" into a simple morality tale: legibility bad, illegibility good. But that’s not what Scott argued and it’s not what reality demands.

Legibility has its place. You want airplanes certified, hospitals regulated, bridges designed to sustain traffic, and payroll systems that balance. In those contexts, standardization saves lives. Making things visible, measurable, and comparable allows complex systems to coordinate and scale. But legibility fails when it wanders into domains that thrive on ambiguity: research, human motivation, culture, creativity, learning, care. It's naive to try to make them fully "data-driven" or "AI-optimized", but even if we succeed temporarily, such legible system will crash sooner or later, after facing an unpredicted event.

The trick, then, is not to reject legibility but to govern its boundaries. For instance use legibility for delivery, when you’re implementing, scaling, or regulating. Use illegibility for discovery, when you’re exploring, empathizing, or creating. As somebody who spent more than decade in academia I have to mention that this is the lesson that scientists need to learn as well - the more they try to make impact of science measurable, the more they make the whole system fragile and prone to gambling.

The challenge is to re-balance legibility. To remember that what makes something measurable doesn’t necessarily make it valuable. The counter-move on a personal level: practicing functional illegibility that is deliberately staying too rich, too fluid, too context-dependent to be neatly categorized.

## Why this matters now
The 20th-century state wanted to make citizens legible. The 21st-century tech industry wants to make jobs and selves legible. Empowerment through clarity is a nice award, but it would be nice if along the way we don't erode the messy, adaptive intelligence that makes life resilient.

Scott claimed that "metis" always survives in the cracks. I think his book remains essential reading not because it explains government failures, but because it explains our moment. Because if we forget that what makes a system efficient often makes it brittle, we’ll end up living inside a world of perfect data — and very little wisdom.